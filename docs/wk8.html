<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gavin Rolls">
<meta name="dcterms.date" content="2024-03-12">

<title>Gavin Rolls - Learning Diary for CASA 0023 - 8&nbsp; Advanced Classification and Accuracy Assesment</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./wk9.html" rel="next">
<link href="./wk7.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./wk8.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Advanced Classification and Accuracy Assesment</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Gavin Rolls - Learning Diary for CASA 0023</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hello!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Remote Sensing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Xaringan Presentation - VIIRS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Image Correction &amp; Data Joining</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Remote Sensing for Urban Policy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Week Off</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Introduction to Earth Engine</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification of Remotely Sensed Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Advanced Classification and Accuracy Assesment</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./wk9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Synthetic Aperture Radar</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="header-section-number">8.1</span> Summary</a>
  <ul class="collapse">
  <li><a href="#object-based-image-analysis" id="toc-object-based-image-analysis" class="nav-link" data-scroll-target="#object-based-image-analysis"><span class="header-section-number">8.1.1</span> Object Based Image Analysis</a></li>
  <li><a href="#sub-pixel-analysis" id="toc-sub-pixel-analysis" class="nav-link" data-scroll-target="#sub-pixel-analysis"><span class="header-section-number">8.1.2</span> Sub-Pixel Analysis</a></li>
  <li><a href="#accuracy-assessment" id="toc-accuracy-assessment" class="nav-link" data-scroll-target="#accuracy-assessment"><span class="header-section-number">8.1.3</span> Accuracy Assessment</a></li>
  <li><a href="#machine-learning-approaches" id="toc-machine-learning-approaches" class="nav-link" data-scroll-target="#machine-learning-approaches"><span class="header-section-number">8.1.4</span> Machine Learning Approaches</a></li>
  </ul></li>
  <li><a href="#applications-in-research" id="toc-applications-in-research" class="nav-link" data-scroll-target="#applications-in-research"><span class="header-section-number">8.2</span> Applications in Research</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">8.3</span> Reflection</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">8.4</span> References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Advanced Classification and Accuracy Assesment</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Gavin Rolls </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 12, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">8.1</span> Summary</h2>
<p>A continuation of last week’s look into the classification of remotely sensed imaging, we focused this week on a handful of more advanced methods, with a particular focus on determining the accuracy of classifications. I will briefly touch on some of those methods before taking the majority of the summary to talk about accuracy assessment.</p>
<section id="object-based-image-analysis" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="object-based-image-analysis"><span class="header-section-number">8.1.1</span> Object Based Image Analysis</h3>
<p>Object based image analysis is a method of analysing remotely sensed data at the multi-pixel or ‘superpixel’ level by identifying discrete physical objects (buildings, small bodies of water, fields, etc…) which can then be classified at object level as opposed to considering pixels in isolation <span class="citation" data-cites="blaschke2010">(<a href="#ref-blaschke2010" role="doc-biblioref">Blaschke 2010</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/OBIA.png" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">A Remotely Sensed Image segmented using OBIA - <span class="citation" data-cites="gisgeography2023">GISGeography (<a href="#ref-gisgeography2023" role="doc-biblioref">2023</a>)</span></figcaption>
</figure>
</div>
<p>The most common way of doing this is an algorithm known as Simple Linear Iterative Clustering, which partitions the image into a grid before iteratively moving the centre of each cell to best capture the pixels which maximise the homogeneity of the chunk, in a manner similar to k-means clustering <span class="citation" data-cites="achanta2012">(<a href="#ref-achanta2012" role="doc-biblioref">Achanta et al. 2012</a>)</span>. This algorithm attempts to keep objects both spatially and spectrally compact, meaning they retain a consistent appearance and a small physical distance from end to end.</p>
</section>
<section id="sub-pixel-analysis" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="sub-pixel-analysis"><span class="header-section-number">8.1.2</span> Sub-Pixel Analysis</h3>
<p>In contrast to analysis at the multi-pixel analysis, sub-pixel analysis concerns the classification of individual pixels when they may fall into multiple land-cover categories. This is particularly important for satellite imagery taken at a low spatial resolution, where individual pixels represent a larger share of land area <span class="citation" data-cites="du2014">(<a href="#ref-du2014" role="doc-biblioref">DU et al. 2014</a>)</span>. A classic method for sub-pixel analysis is multiple endmember spectral mixture analysis, also known as MESMA, which attempts to identify the proportion of each landcover type within each pixel. To do this, each pixel’s spectral signature is compared against endmembers (spectral representations of landcover types - often but not always soil, vegetation, and impervious surfaces) to identify the endmembers which most contributed to the pixel’s ‘mixed signature’ <span class="citation" data-cites="quintano2013">(<a href="#ref-quintano2013" role="doc-biblioref">Quintano, Fernández-Manso, and Roberts 2013</a>)</span>. This process is known as unmixing - basically breaking a pixel down into its constituent landcover components.</p>
</section>
<section id="accuracy-assessment" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="accuracy-assessment"><span class="header-section-number">8.1.3</span> Accuracy Assessment</h3>
<p>The key issue we focused on in lecture (and which I would like to focus on in this review) is that of determining how accurately a landcover classification algorithm has actually divided an image. There are two key accuracy metrics to consider:</p>
<ol type="1">
<li><strong>Producer’s Accuracy</strong><br>
Producer’s accuracy, or PA, is the percentage of pixels correctly classified by landcover <span class="citation" data-cites="barsi2018">(<a href="#ref-barsi2018" role="doc-biblioref">Barsi et al. 2018</a>)</span>. In other words, if I select a pixel that’s ‘bare earth’, what’s the likelihood that it has been classified as bare earth by our algorithm?</li>
<li><strong>User’s Accuracy<br>
</strong>User’s Accuracy is a measure of the proportion of pixels classified as a particular class which actually belong to that class <span class="citation" data-cites="barsi2018">(<a href="#ref-barsi2018" role="doc-biblioref">Barsi et al. 2018</a>)</span>. In other words, if I select a random pixel which was classified as ‘bare earth’, what’s the likelihood that it’s actually bare earth?</li>
</ol>
<p>There is an inherent trade-off between these two metrics - if an algorithm is ‘quick to classify’ pixels as a certain class when they may not belong to that class, it ensures that all pixels of that class are captured but the algorithm may also capture pixels not belonging to that class. On the other hand, an algorithm which only classifies pixels as a given class when it’s absolutely positive is one for which you can assume those pixels to be of that class with a high degree of confidence, but there will likely be many pixels of that class not captured by the algorithm.</p>
<p>There are a handful of metrics which attempt to capture, in a single statistic, the accuracy of a classification algorithm. One of the most widely used, the Kappa coefficient, attempts to measure how well a model classifies an image when compared to an algorithm randomly classifying pixels <span class="citation" data-cites="foody2020">(<a href="#ref-foody2020" role="doc-biblioref">Foody 2020</a>)</span>. There are, however, a number of issues with the measure with some arguing that it is difficult to interpret and doesn’t accurately capture ‘chance agreement’ as intended <span class="citation" data-cites="foody2020">(<a href="#ref-foody2020" role="doc-biblioref">Foody 2020</a>)</span>.</p>
</section>
<section id="machine-learning-approaches" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="machine-learning-approaches"><span class="header-section-number">8.1.4</span> Machine Learning Approaches</h3>
<p>Finally, we touched on a handful of approaches which deploy machine learning to in order to maximise classification accuracy. The basic principle underlying these principles is that a model trained on a particular dataset will then be tested against a portion of that dataset which it has not yet seen. Typically this means that a dataset will be subdivided into folds, where each fold can be used as a test set for an algorithm trained on all other folds <span class="citation" data-cites="stock2022">(<a href="#ref-stock2022" role="doc-biblioref">Stock and Subramaniam 2022</a>)</span>. One version of this approach, known as ‘leave-one-out cross-validation’, uses a number of folds equivalent to the number of observations in the dataset, effectively testing each algorithm on a single data point <span class="citation" data-cites="stock2022">(<a href="#ref-stock2022" role="doc-biblioref">Stock and Subramaniam 2022</a>)</span>.</p>
<p>A key issue, unique to spatial data, arises in the form of spatial autocorrelation. If our testing and training data are in close proximity, they’re likely to be similar to each other. The test set is unlikely, then, to represent a novel sort of data which can accurately assess the algorithm at hand. A solution comes in the form of random k-fold cross-validation, where the data is not split randomly but spatially, and individual folds are spatially non-overlapping <span class="citation" data-cites="wang2023">(<a href="#ref-wang2023" role="doc-biblioref">Wang, Zhodadadzadeh, and Zurita-Milla 2023</a>)</span>. More advanced methods will further subdivide these folds into inner folds and test multiple models with randomly selected parameters in attempt to find the best possible model.</p>
</section>
</section>
<section id="applications-in-research" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="applications-in-research"><span class="header-section-number">8.2</span> Applications in Research</h2>
<p>For this section I will discuss both a paper that expands on the methods described above as well as one which applies these methods for a particular use case.</p>
<p><span class="citation" data-cites="stock2022">Stock and Subramaniam (<a href="#ref-stock2022" role="doc-biblioref">2022</a>)</span> propose a novel method of leave-one-out cross-validation, which they call iterative spatial leave-one-out cross-validation, or iSLOOCV. Typical spatial leave-one-out cross-validation (SLOOCV) works by excluding any observations within a certain distance <span class="math inline">\(r\)</span> of the single test set variable to avoid spatial autocorrelation effects. The method proposed by <span class="citation" data-cites="stock2022">Stock and Subramaniam (<a href="#ref-stock2022" role="doc-biblioref">2022</a>)</span> introduces an iterative element, wherein <span class="math inline">\(r\)</span> is varied from 100 metres to 200 kilometres in order to identify shifts in error over the different threshold differences and identify the minimum separation required to avoid spatial autocorrelation effects.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/SLOOCV.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">iSLOOCV applied to a set of observations in the Gulf of Mexico - <span class="citation" data-cites="stock2022">Stock and Subramaniam (<a href="#ref-stock2022" role="doc-biblioref">2022</a>)</span></figcaption>
</figure>
</div>
<p>An application of Object-based image analysis which is of particular interest to me is its use in change detection. Given the nature of change (as seen from above) as often concerned with changes in discrete objects at ground-level, it’s easy to see why object-based methods are a sensible choice. <span class="citation" data-cites="im2008">Im, Jensen, and Tullis (<a href="#ref-im2008" role="doc-biblioref">2008</a>)</span> develop a new method of change detection attempting to evaluate changes in landcover at the object level. To do this, they normalise data across their two images (before and after) and extract reference points which are classified into five ‘unchanged classes’ (landcover was the same between both images) and three ‘change classes’, representing examples of different types of change. They then applied nearest-neighbour and decision tree classification algorithms to their images in order to generate what they called an ‘object correlation image’. They then compared their results against images generated by an existing methodology (neighbourhood correlation image) which classified local, multi-pixel areas but didn’t use any sort of object detection. Object-based performed the best classification and had higher kappa values than the neighbourhood-based analysis (although as discussed previously, kappa coefficients are not a bulletproof metric).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/OCI:NCI.png" class="img-fluid figure-img" width="800"></p>
<figcaption class="figure-caption">Change detection results and corresponding class key from a Las Vegas neighbourhood - <span class="citation" data-cites="im2008">Im, Jensen, and Tullis (<a href="#ref-im2008" role="doc-biblioref">2008</a>)</span></figcaption>
</figure>
</div>
</section>
<section id="reflection" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">8.3</span> Reflection</h2>
<p>In my opinion, the most telling lesson amidst the topics discussed on remote sensing classes is that of the Kappa coefficient. It’s a reminder to me that even in an academic setting, where one would hope that accuracy is paramount, established methods can take hold even when reasonable alternatives exist. I was surprised to see in <span class="citation" data-cites="im2008">Im, Jensen, and Tullis (<a href="#ref-im2008" role="doc-biblioref">2008</a>)</span> that the metrics being used to show accuracy were Producer’s accuracy, User’s accuracy, and the Kappa coefficient. No other accuracy metrics were provided. Additionally, the coefficients generated were all within a narrow, 4% band making it difficult to understand a) how good the classifiers are in general and b) if the new object-based method is really all that much better than existing methods.</p>
<p>I’ve already encountered the use of some of the more robust accuracy metrics we discussed in class when doing research for our group presentation assessment, such the Receiver Operating Characteristic Curve (the details for which I omitted to save space). To that end, I know preferable metrics can be used with relative ease so the lag in adoption is interesting to see.</p>
</section>
<section id="references" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="references"><span class="header-section-number">8.4</span> References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-achanta2012" class="csl-entry" role="listitem">
Achanta, Radhakrishna, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Süsstrunk. 2012. <span>“SLIC Superpixels Compared to State-of-the-Art Superpixel Methods.”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 34 (11): 2274–82. <a href="https://doi.org/10.1109/TPAMI.2012.120">https://doi.org/10.1109/TPAMI.2012.120</a>.
</div>
<div id="ref-barsi2018" class="csl-entry" role="listitem">
Barsi, Á, Zs Kugler, I. László, Gy Szabó, and H. M. Abdulmutalib. 2018. <span>“Accuracy Dimensions in Remote Sensing.”</span> <em>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em> XLII-3 (April): 61–67. <a href="https://doi.org/10.5194/isprs-archives-XLII-3-61-2018">https://doi.org/10.5194/isprs-archives-XLII-3-61-2018</a>.
</div>
<div id="ref-blaschke2010" class="csl-entry" role="listitem">
Blaschke, T. 2010. <span>“Object Based Image Analysis for Remote Sensing.”</span> <em>ISPRS Journal of Photogrammetry and Remote Sensing</em> 65 (1): 2–16. <a href="https://doi.org/10.1016/j.isprsjprs.2009.06.004">https://doi.org/10.1016/j.isprsjprs.2009.06.004</a>.
</div>
<div id="ref-du2014" class="csl-entry" role="listitem">
DU, Peijun, Sicong LIU, Pei LIU, Kun TAN, and Liang CHENG. 2014. <span>“Sub-Pixel Change Detection for Urban Land-Cover Analysis via Multi-Temporal Remote Sensing Images.”</span> <em>Geo-Spatial Information Science</em> 17 (1): 26–38. <a href="https://doi.org/10.1080/10095020.2014.889268">https://doi.org/10.1080/10095020.2014.889268</a>.
</div>
<div id="ref-foody2020" class="csl-entry" role="listitem">
Foody, Giles M. 2020. <span>“Explaining the Unsuitability of the Kappa Coefficient in the Assessment and Comparison of the Accuracy of Thematic Maps Obtained by Image Classification.”</span> <em>Remote Sensing of Environment</em> 239 (March): 111630. <a href="https://doi.org/10.1016/j.rse.2019.111630">https://doi.org/10.1016/j.rse.2019.111630</a>.
</div>
<div id="ref-gisgeography2023" class="csl-entry" role="listitem">
GISGeography. 2023. <span>“OBIA - Object-Based Image Analysis (GEOBIA) - GIS Geography.”</span> <a href="https://gisgeography.com/obia-object-based-image-analysis-geobia/">https://gisgeography.com/obia-object-based-image-analysis-geobia/</a>.
</div>
<div id="ref-im2008" class="csl-entry" role="listitem">
Im, J., J. R. Jensen, and J. A. Tullis. 2008. <span>“Object<span>-</span>Based Change Detection Using Correlation Image Analysis and Image Segmentation.”</span> <em>International Journal of Remote Sensing</em> 29 (2): 399–423. <a href="https://doi.org/10.1080/01431160601075582">https://doi.org/10.1080/01431160601075582</a>.
</div>
<div id="ref-quintano2013" class="csl-entry" role="listitem">
Quintano, Carmen, Alfonso Fernández-Manso, and Dar A. Roberts. 2013. <span>“Multiple Endmember Spectral Mixture Analysis (MESMA) to Map Burn Severity Levels from Landsat Images in Mediterranean Countries.”</span> <em>Remote Sensing of Environment</em> 136 (September): 76–88. <a href="https://doi.org/10.1016/j.rse.2013.04.017">https://doi.org/10.1016/j.rse.2013.04.017</a>.
</div>
<div id="ref-stock2022" class="csl-entry" role="listitem">
Stock, Andy, and Ajit Subramaniam. 2022. <span>“Iterative Spatial Leave-One-Out Cross-Validation and Gap-Filling Based Data Augmentation for Supervised Learning Applications in Marine Remote Sensing.”</span> <em>GIScience &amp; Remote Sensing</em> 59 (1): 1281–1300. <a href="https://doi.org/10.1080/15481603.2022.2107113">https://doi.org/10.1080/15481603.2022.2107113</a>.
</div>
<div id="ref-wang2023" class="csl-entry" role="listitem">
Wang, Yanwen, Mahdi Zhodadadzadeh, and Raúl Zurita-Milla. 2023. <span>“Spatial+: A New Cross-Validation Method to Evaluate Geospatial Machine Learning Models.”</span> <em>International Journal of Applied Earth Observation and Geoinformation</em> 121 (July): 103364. <a href="https://doi.org/10.1016/j.jag.2023.103364">https://doi.org/10.1016/j.jag.2023.103364</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./wk7.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification of Remotely Sensed Data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./wk9.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Synthetic Aperture Radar</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>